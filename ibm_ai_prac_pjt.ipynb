{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c237ced6",
   "metadata": {},
   "source": [
    "# Project Background:\n",
    "\n",
    "#### Companies often receive thousands of resumes for each job posting and employ dedicated screening officers to screen qualified candidates.\n",
    "\n",
    "#### Hiring the right talent is a challenge for all businesses. This challenge is magnified by the high volume of applicants if the business is labour-intensive, growing, and facing high attrition rates.\n",
    "\n",
    "#### IT departments are short of growing markets. In a typical service organization, professionals with a variety of technical skills and business domain expertise are hired and assigned to projects to resolve customer issues. This task of selecting the best talent among many others is known as Resume Screening.\n",
    "\n",
    "<img src=\"giphy.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40cc376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk import bigrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import docx2txt\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3b0c7",
   "metadata": {},
   "source": [
    "## Concatenate new resumes into resume dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e179b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [x for x in os.listdir('./resumes') if x.endswith(\".docx\")]\n",
    "print(doc_list)\n",
    "\n",
    "for doc in doc_list:\n",
    "\n",
    "        resume = docx2txt.process(f'./resumes/{doc}')\n",
    "        resume = pd.DataFrame({'Resume': resume}, index=[1])\n",
    "        df_resume = pd.concat([df_resume, resume], ignore_index=True)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6998e5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[962, 963, 964, 965]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "962    candidate details\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\...\n",
       "963    candidate details\\n\\n\\n\\nname\\t\\t\\t\\t\\t: Xisi\\...\n",
       "964    Yang Gui Fei\\n\\n101 Ang Mo Kio Avenue 1 • #02-...\n",
       "965    POSITION\\n\\nBusiness Analyst\\n\\n\\n\\n\\n\\nPERSON...\n",
       "Name: Resume, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = df_resume.index[df_resume['Category'].isnull()].tolist()\n",
    "print(start_idx)\n",
    "df_resume['Resume'][start_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddfe6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = docx2txt.process('./Job_description/JD Business Analyst.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_array[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7921523",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_score_dict = {}\n",
    "score_list = []\n",
    "count = CountVectorizer()\n",
    "for idx in start_idx:\n",
    "    text = [df_resume['Resume'][idx], jd]\n",
    "    count_matrix = count.fit_transform(text)\n",
    "    score_list.append(cos_sim(count_matrix)[0][1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e47d8e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_score_dict = { doc_list [idx] : round(score_list[idx], 2) for idx in range(len(score_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb683425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_score(dict):\n",
    "    \n",
    "    sorted_dict = sorted(dict, key=dict.get, reverse=True)\n",
    "    for val in sorted_dict[:3]:\n",
    "        print(f'{val} : {dict[val]}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea4c5fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume - Xisi.docx : 0.77\n",
      "ChenMeiMei.docx : 0.71\n",
      "Resume - YangGuiFei.docx : 0.71\n"
     ]
    }
   ],
   "source": [
    "rank_score(doc_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9cbef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd922788",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_array = cos_sim(count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04051bdc",
   "metadata": {},
   "source": [
    "# Objective 1: Filter Resume based on Job Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5def504",
   "metadata": {},
   "source": [
    "## Read Dataset to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a53513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume = pd.read_csv('resume_dataset.csv')\n",
    "jd_df = pd.read_csv('jd_data.csv', encoding='cp1252')\n",
    "jd_df.rename(columns = {'JD':'Resume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c502bf",
   "metadata": {},
   "source": [
    "## Merge JD and Resume dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume = pd.concat([df_resume, jd_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d1a780",
   "metadata": {},
   "source": [
    "## Exploratory Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcacffc",
   "metadata": {},
   "source": [
    "### Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be40dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d8c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6177c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9ff56",
   "metadata": {},
   "source": [
    "### Distribution of Job Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869bc67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax=sns.countplot(x=\"Category\", data=df_resume[:962], order=df_resume['Category'].value_counts().index, palette=\"husl\")\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db78b99b",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6701a227",
   "metadata": {},
   "source": [
    "### Removed Unusual Characters using Regular Expression (Regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unusual_text_remover(text):\n",
    "    text = re.sub('â\\x80¢Â', ' ', text)\n",
    "    text = re.sub('â\\x9c¶', ' ', text)\n",
    "    text = re.sub('Ã¼Â', ' ', text)\n",
    "    text = re.sub('Â', '', text)\n",
    "    text = re.sub('Ã¼', '', text)\n",
    "    text = re.sub('ï', '', text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "usual_text = df_resume['Resume'].apply(unusual_text_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86069e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume['Processed_Resume'] = df_resume['Resume'].apply(unusual_text_remover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3c959",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b56d1",
   "metadata": {},
   "source": [
    "### Convert root word using Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3951628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = word_tokenize(text)\n",
    "    output = ' '.join([lemmatizer.lemmatize(word) for word in word_list])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ede9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_text = usual_text.apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d498138",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume['Processed_Resume'] = df_resume['Processed_Resume'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d8080",
   "metadata": {},
   "source": [
    "### Resume before data cleaning and preprocessing (in-progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eab47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume.iloc[18,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9253d2c9",
   "metadata": {},
   "source": [
    "### Resume after data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6400a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "usual_text[18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce2c03",
   "metadata": {},
   "source": [
    "### Resume after data cleaning and preprocessing (in-progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfddb3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_text[18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0905d4",
   "metadata": {},
   "source": [
    "## Filter Resume based on keywords and Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b282c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.DataFrame()  \n",
    "\n",
    "key_words = ['12 month', '1 year', 'python']\n",
    "role = 'Data Science'\n",
    "\n",
    "for idx in range(df_resume.shape[0]):\n",
    "    sentence = df_resume['Processed_Resume'][idx]  \n",
    "    twogram = bigrams(sentence.split())\n",
    "    for gram in twogram:\n",
    "        try:\n",
    "            if (gram[0] + ' ' + gram[1]) in key_words and df_resume.iloc[[idx]]['Category'].values[0] == role:\n",
    "                    df_filtered =  df_filtered.append(df_resume.iloc[[idx]])\n",
    "        \n",
    "        except KeyError:\n",
    "            df_filtered =  df_filtered.append(df_resume.iloc[[idx]])\n",
    "             \n",
    "df_filtered.drop_duplicates(subset=['Processed_Resume'], inplace=True)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f570d7",
   "metadata": {},
   "source": [
    "### Write Dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ae667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('filtered_resume.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24904ea3",
   "metadata": {},
   "source": [
    "# Objective 2: Classify Job Category from Incoming Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9950933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b350120",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720efcfb",
   "metadata": {},
   "source": [
    "### Remove Stop-words in Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c96a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b698fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words =[]\n",
    "sentences = []\n",
    "for text in df_resume['Processed_Resume']:\n",
    "    word_list = word_tokenize(text)\n",
    "    para = [word for word in word_list if word not in stop]\n",
    "    sentences.append(' '.join(para))\n",
    "    total_words = total_words + para\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreqdist = nltk.FreqDist(' '.join(total_words))\n",
    "mostcommon = wordfreqdist.most_common(50)\n",
    "print(mostcommon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud().generate(' '.join(total_words))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40788dbe",
   "metadata": {},
   "source": [
    "### Transform words into feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18274d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68084622",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(use_idf=True, norm = 'l2', smooth_idf =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb84f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit_transform(count.fit_transform(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision= 2)\n",
    "a = tfidf.fit_transform(count.fit_transform(sentences)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3947e2d3",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76edc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_resume['Category'][:962]\n",
    "x = a[:962]\n",
    "x_test_jd = a[962:]\n",
    "y_test_jd = df_resume['Category'][962:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(x.shape)\n",
    "print(y_test_jd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314550f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x, y,random_state=42, test_size=0.3,\n",
    "                                                 shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object clf from class OneVsRestClassifier and KNeighborsClassifier\n",
    "clf = OneVsRestClassifier(KNeighborsClassifier())\n",
    "# Input training sets into the object (model)\n",
    "clf.fit(X_train, y_train)\n",
    "# Predict target variable by using test set on the trained model\n",
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(clf.score(X_train, y_train),3))\n",
    "print(round(clf.score(X_test, y_test),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358596b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{clf} \\n')\n",
    "print(metrics.classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150fccd",
   "metadata": {},
   "source": [
    "# Objective 3: Run JD data on trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec17bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_prediction = clf.predict(x_test_jd)\n",
    "print(jd_prediction)\n",
    "print(y_test_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{clf} \\n')\n",
    "print(metrics.classification_report(y_test_jd, jd_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
